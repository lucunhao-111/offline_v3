#国庆假期任务：
1. Minio 安装
   可安装单节点或分布式的 minio , 本地部署或者 docker 都可
   minio 上传⼀个 csv ⽂件, 使⽤ hive 映射该⽂件为表, hive 可查询, 能实现 ds 分区为佳, 使⽤时间分区, ds=20250925
![img_20.png](img%2Fimg_20.png)
![img_21.png](img%2Fimg_21.png)
![img_22.png](img%2Fimg_22.png)
![img_23.png](img%2Fimg_23.png)
![img_24.png](img%2Fimg_24.png)
2. CDH 安装 hbase
   创建 hbase 表, 数据由 Flink 写⼊ FlinkAPI 或者 FlinkSQL 都可以
   hbase rowkey 的设计, 符合企业原则![img.png](img.png)
   hbase 数据进⼊后, 使⽤ hive 和 hbase 的映射表进⾏映射, 数据需要可查询, 实现可分区为佳
![img_26.png](img%2Fimg_26.png)
![img_28.png](img%2Fimg_28.png)
![img_29.png](img%2Fimg_29.png)
![img_30.png](img%2Fimg_30.png)
![img_1.png](img_1.png)
   这是一个整体的流程，Hbase 建表已经利用 flink_cdc 进行写数据到 hive 中，然后对于 hive 我们进行了一个验证，也是很正确的。

3. python spider 爬⾍
   3.1 爬取中国⽓象数据, 数据要求 10 s 更新⼀次，增量更新
   3.2 爬取中国外汇当⽇市场数据数据 10 s 更新⼀次，增量更新
   ps : 环境可移植, 代码需要在 linux 中可运⾏, 使⽤ conda 环境进⾏配置, 配置反爬⼿段进⾏预防

- 天气爬虫思路：
- 支持手动添加各城市映射，已内置部分城市，后期可自行扩展；
- 先获取天气接口URL，添加User-Agent应对反爬；
- 获取7天天气数据，将得到的JSON文件存入指定文件夹，便于管理；
- 因每10秒更新一次易产生重复数据，故添加数据判断逻辑，与上一条数据对比，无变化则不新增JSON文件。

- 汇率爬虫操作：
- 操作流程与天气爬虫基本一致，先找到汇率接口URL，再做反爬处理；
- 将获取到的汇率数据存入指定目录；
- 同样添加数据判断逻辑，与上一条数据对比，无变化则不产生新数据。




4. 使⽤ VLLM 框架部署 Qwen3-0.6B 模型, 模型需要⽀持 RestFul 接⼝的调⽤
   4.1 qwen 模型使⽤ 2 种⽅式进⾏部署分别是基于 CPU 和 GPU 运⾏
   4.2 qwen 模型使⽤云端进⾏部署, 开放远程调⽤的 callback
   4.3 qwen 模型需要微调, 使⽤ LoRA 框架预先训练数据集, 针对地址信息进⾏调整, 数据处理使⽤ PySpark
完全不知道怎么写。



5. 安装 PostGreSQL & SQLServer &Doris-2.1.6V 数据库 (linux)
   分别创建 2 张表, 使⽤ FlinkCDC 读取这两张表的数据, 并写⼊下游的 Kafka 主题中, 使⽤ doris 的 Roadtime Load ⽅式
   进⾏数据加载, 使⽤动态分区，使⽤分桶
![img_25.png](img%2Fimg_25.png)
安装了组间，中间并未写，有点理不清思路。




6. 安装 FineReport 11 Version
![img_31.png](img%2Fimg_31.png)